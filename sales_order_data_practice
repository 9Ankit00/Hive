#Store raw data into hdfs location
hadoop fs -put /home/cloudera/Desktop/Hive-Class-main/sales_order_data.csv  /tmp/hive_data_class/

#To check data is present in hdfs location
hadoop fs -ls /tmp/hive_data_class
Found 2 items
-rw-r--r--   1 cloudera supergroup        655 2022-09-12 14:15 /tmp/hive_data_class/depart_data.csv
-rw-r--r--   1 cloudera supergroup     360233 2022-09-18 08:24 /tmp/hive_data_class/sales_order_data.csv

#Create a internal hive table "sales_order_csv" which will store csv data sales_order_csv .. make sure to skip header row while creating table
hive> use hive_class_b1;
OK
Time taken: 0.022 seconds
hive> create table sales_order_csv(
    > ORDERNUMBER int,
    > QUANTITYORDERED int,
    > PRICEEACH float,
    > ORDERLINENUMBER int,
    > SALES FLOAT,
    > STATUS string,
    > QTR_ID int,
    > MONTH_ID int,
    > YEAR_ID int,
    > PRODUCTLINE string,
    > MSRP int,
    > PRODUCTCODE string,
    > PHONE string,
    > CITY string,
    > STATE string,
    > POSTALCODE string,
    > COUNTRY string,
    > TERRITORY string,
    > CONTACTLASTNAME string,
    > CONTACTFIRSTNAME string,
    > DEALSIZE string
    > )
    > row format delimited
    > fields terminated by ','
    > TBLPROPERTIES("skip.header.line.count"="1");
OK
hive> describe sales_order_csv;
OK
ordernumber         	int                 	                    
quantityordered     	int                 	                    
priceeach           	float               	                    
orderlinenumber     	int                 	                    
sales               	float               	                    
status              	string              	                    
qtr_id              	int                 	                    
month_id            	int                 	                    
year_id             	int                 	                    
productline         	string              	                    
msrp                	int                 	                    
productcode         	string              	                    
phone               	string              	                    
city                	string              	                    
state               	string              	                    
postalcode          	string              	                    
country             	string              	                    
territory           	string              	                    
contactlastname     	string              	                    
contactfirstname    	string              	                    
dealsize            	string              	                    
Time taken: 0.163 seconds, Fetched: 21 row(s)

#Load data from hdfs path into "sales_order_csv" 
hive> load data inpath '/tmp/hive_data_class/' into table sales_order_csv;
Loading data to table hive_class_b1.sales_order_csv
Table hive_class_b1.sales_order_csv stats: [numFiles=1, numRows=0, totalSize=360233, rawDataSize=0]
OK
Time taken: 0.322 seconds

hive> select  * from sales_order_csv limit 2;
OK
10107	30	95.7	2	2871.0	Shipped	1	2	2003	Motorcycles	95	S10_1678	2125557818	NYC	NY	10022	USA	NA	Yu	Kwai	Small
10121	34	81.35	5	2765.9	Shipped	2	5	2003	Motorcycles	95	S10_1678	26.47.1555	Reims		51100	FranceEMEA	Henriot	Paul	Small
Time taken: 0.254 seconds, Fetched: 2 row(s)


Time taken: 0.19 seconds

#Create an internal hive table which will store data in ORC format "sales_order_orc"
hive> create table sales_order_orc
    > (
    > ORDERNUMBER int,
    > QUANTITYORDERED int,
    > PRICEEACH float,
    > ORDERLINENUMBER int,
    > SALES float,
    > STATUS string,
    > QTR_ID int,
    > MONTH_ID int,
    > PRODUCTLINE string,
    > MSRP int,
    > PRODUCTCODE string,
    > PHONE string,
    > CITY string,
    > STATE string,
    > POSTALCODE string,
    > TERRITORY string,
    > CONTACTLASTNAME string,
    > CONTACTFIRSTNAME string,
    > DEALSIZE string
    > )
    > partitioned by (country string,year_id int)
    > stored as orc
    > ;
OK
Time taken: 0.394 second
 


#Load data from "sales_order_csv" into "sales_order_orc"
hive> insert overwrite table sales_order_orc partition(country,year_id) 
    > select 
    > ORDERNUMBER ,
    > QUANTITYORDERED ,
    > PRICEEACH ,
    > ORDERLINENUMBER ,
    > SALES ,
    > STATUS ,
    > QTR_ID ,
    > MONTH_ID ,
    > PRODUCTLINE ,
    > MSRP ,
    > PRODUCTCODE ,
    > PHONE ,
    > CITY ,
    > STATE ,
    > POSTALCODE ,
    > TERRITORY ,
    > CONTACTLASTNAME ,
    > CONTACTFIRSTNAME ,
    > DEALSIZE ,
    > country,year_id
    > 
    > from sales_order_csv;
 
#a. Calculatye total sales per year
hive> set mapreduce.jobs.reduces=5;
hive> select year_id, sum(sales) as total_sales from sales_order_orc group by year_id;
Query ID = cloudera_20220922162222_4fc802b5-47c3-4947-ba21-00dcb03d1b9e
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1663884288379_0015, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1663884288379_0015/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1663884288379_0015
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-09-22 16:22:52,449 Stage-1 map = 0%,  reduce = 0%
2022-09-22 16:22:58,831 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.29 sec
2022-09-22 16:23:05,132 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.85 sec
MapReduce Total cumulative CPU time: 3 seconds 850 msec
Ended Job = job_1663884288379_0015
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.85 sec   HDFS Read: 258754 HDFS Write: 70 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 850 msec
OK
2003	3516979.547241211
2004	4724162.593383789
2005	1791486.7086791992

